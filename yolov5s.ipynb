{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebiqLMsyV4yi"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\",force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hySCGWBcDjx"
      },
      "outputs": [],
      "source": [
        "txt = \"Hello World\"\n",
        "fontsize = 1 \n",
        "font = ImageFont.truetype(\"arial.ttf\", fontsize)\n",
        "while font.getsize(txt)[0] < img_fraction*image.size[0]:\n",
        "    # iterate until the text size is just larger than the criteria\n",
        "    fontsize += 1\n",
        "    font = ImageFont.truetype(\"arial.ttf\", fontsize)\n",
        "\n",
        "# optionally de-increment to be sure it is less than criteria\n",
        "fontsize -= 1\n",
        "font = ImageFont.truetype(\"arial.ttf\", fontsize)\n",
        "\n",
        "print('final font size',fontsize)\n",
        "draw.text((10, 25), txt, font=font) # put the text on the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJB7k2XGWXO8",
        "outputId": "96e8e573-fc85-489a-f14e-56a91c48ed79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: './content/gdrive/MyDrive/trash_ICRA19/dataset/'\n",
            "/\n"
          ]
        }
      ],
      "source": [
        "%cd ./content/gdrive/MyDrive/trash_ICRA19/dataset/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwTcBhTuUgXj",
        "outputId": "7d6ce76d-900e-4ac3-9cbe-0fb9d4ad9889"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mbin\u001b[0m/      \u001b[01;34mdev\u001b[0m/   \u001b[01;34mlib32\u001b[0m/  \u001b[01;34mopt\u001b[0m/         \u001b[01;34mrun\u001b[0m/   \u001b[01;34mtensorflow-1.15.2\u001b[0m/  \u001b[01;34mvar\u001b[0m/\n",
            "\u001b[01;34mboot\u001b[0m/     \u001b[01;34metc\u001b[0m/   \u001b[01;34mlib64\u001b[0m/  \u001b[01;34mproc\u001b[0m/        \u001b[01;34msbin\u001b[0m/  \u001b[30;42mtmp\u001b[0m/\n",
            "\u001b[01;34mcontent\u001b[0m/  \u001b[01;34mhome\u001b[0m/  \u001b[01;34mmedia\u001b[0m/  \u001b[01;34mpython-apt\u001b[0m/  \u001b[01;34msrv\u001b[0m/   \u001b[01;34mtools\u001b[0m/\n",
            "\u001b[01;34mdatalab\u001b[0m/  \u001b[01;34mlib\u001b[0m/   \u001b[01;34mmnt\u001b[0m/    \u001b[01;34mroot\u001b[0m/        \u001b[01;34msys\u001b[0m/   \u001b[01;34musr\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ua7MxsCGqbZf"
      },
      "source": [
        "# Training Dataset before augumentation\n",
        "###BIO - 1362\n",
        "###Plastic- 3931\n",
        "###ROV-428\n",
        "---\n",
        "#Validate Dataset\n",
        "###820 Image\n",
        "---\n",
        "#Testing dataset\n",
        "###1144 images \n",
        "\n",
        "#Class Label\n",
        "###bio-1\n",
        "###plastic-0\n",
        "###rov-2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jMTAYinSTJH",
        "outputId": "3e51398d-9cef-42b6-f127-f2fdbb9f7cfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'yolov5'\n",
            "/content\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\n",
            "/\n"
          ]
        }
      ],
      "source": [
        "%cd yolov5\n",
        "!pip install -r requirements.txt\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TonMRC9qSYFA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from IPython.display import Image  # for displaying images\n",
        "import os \n",
        "import random\n",
        "import shutil\n",
        "import xml.etree.ElementTree as ET\n",
        "from xml.dom import minidom\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUghfHx_UAsn"
      },
      "outputs": [],
      "source": [
        "path=\"./\"\n",
        "txt_files = glob.glob(path+\"*.txt\")\n",
        "train=glob.glob(path+\"*.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMIDBPLiSva3"
      },
      "outputs": [],
      "source": [
        "def plot_bounding_box(image, annotation_list):\n",
        "    annotations = np.array(annotation_list)\n",
        "    w, h = image.size\n",
        "    class_id_to_name_mapping=['Plastic','Bio','ROV']\n",
        "    plotted_image = ImageDraw.Draw(image)\n",
        "\n",
        "    transformed_annotations = np.copy(annotations)\n",
        "    transformed_annotations[:,[1,3]] = annotations[:,[1,3]] * w\n",
        "    transformed_annotations[:,[2,4]] = annotations[:,[2,4]] * h \n",
        "    \n",
        "    transformed_annotations[:,1] = transformed_annotations[:,1] - (transformed_annotations[:,3] / 2)\n",
        "    transformed_annotations[:,2] = transformed_annotations[:,2] - (transformed_annotations[:,4] / 2)\n",
        "    transformed_annotations[:,3] = transformed_annotations[:,1] + transformed_annotations[:,3]\n",
        "    transformed_annotations[:,4] = transformed_annotations[:,2] + transformed_annotations[:,4]\n",
        "    \n",
        "    for ann in transformed_annotations:\n",
        "        obj_cls, x0, y0, x1, y1 = ann\n",
        "        plotted_image.rectangle(((x0,y0), (x1,y1)),outline=\"black\",width=3)\n",
        "        plotted_image.text((x0, y0 - 10), class_id_to_name_mapping[(int(obj_cls))])\n",
        "  \n",
        "    plt.imshow(np.array(image))\n",
        "    plt.show()\n",
        "\n",
        "# Get any random annotation file \n",
        "annotation_file = txt_files[780]\n",
        "with open(annotation_file, \"r\") as file:\n",
        "    annotation_list = file.read().split(\"\\n\")[:-1]\n",
        "    annotation_list = [x.split(\" \") for x in annotation_list]\n",
        "    annotation_list = [[float(y) for y in x ] for x in annotation_list]\n",
        "\n",
        "#Get the corresponding image file\n",
        "# image_file = annotation_file.replace(\"annotations\", \"images\").replace(\"txt\", \"png\")\n",
        "# assert os.path.exists(\"./bio0000_frame0000065.jpg.jpg\")\n",
        "\n",
        "#Load the image\n",
        "image = Image.open(train[780])\n",
        "\n",
        "#Plot the Bounding Box\n",
        "plot_bounding_box(image, annotation_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hXvIFa1WVaT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "58d1a76a-e927-47d6-f631-aa170642c31a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/.shortcut-targets-by-id/1wiYTA8v9a4HYq9Vf2eG-DhBAPLA6AGa4/trash_ICRA19/dataset/train'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSzlKOqzRSiK"
      },
      "source": [
        "YOLO from NG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yhi6Uyn3TcuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3ac26f7-bdda-44e7-ed31-833c536dd0ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1wiYTA8v9a4HYq9Vf2eG-DhBAPLA6AGa4/trash_ICRA19/dataset\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5teR_SFHFiME"
      },
      "source": [
        "YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgmYTXO0IGzn"
      },
      "source": [
        "https://towardsdatascience.com/object-detection-on-newspaper-images-using-yolov3-85acfa563080\n",
        "https://github.com/imvab/news-yolo/blob/master/newspaper-yolo.cfg\n",
        "\n",
        "https://github.com/gautamtata/DeepPlastic/blob/master/DeepTrash_Yolov5.ipynb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rARP7F0FjTh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b18539-b905-4fa8-81af-8ec519f00834"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5/yolov5s.pt, cfg=/content/gdrive/MyDrive/CopyTrash/dataset/yolov5/models/inc.yaml, data=/content/gdrive/MyDrive/CopyTrash/dataset/yolov5/deep_sea_kv.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=11, batch_size=8, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=yoloIncKV, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=3, freeze=[0], save_period=1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mâš ï¸ YOLOv5 is out of date by 97 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
            "YOLOv5 ðŸš€ v6.1-35-g932dc78 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
            "  1                -1  1     13120  models.common.Conv                      [80, 160, 1, 2]               \n",
            "  2                -1  1    230720  models.common.Conv                      [160, 160, 3, 1]              \n",
            "  3                 1  1    640320  models.common.Conv                      [160, 160, 5, 1]              \n",
            "  4                 0  1         0  torch.nn.modules.pooling.MaxPool2d      [3, 2, 1]                     \n",
            "  5      [1, 2, 3, 4]  1         0  models.common.Concat                    [1]                           \n",
            "  6                -1  4    373120  models.common.C3                        [560, 160, 4]                 \n",
            "  7                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
            "  8                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
            "  9                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
            " 10                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
            " 11                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
            " 12                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
            " 13                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
            " 14                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
            " 18                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
            " 19                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 20           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 21                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
            " 22                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
            " 23          [-1, 18]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
            " 25                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
            " 26          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 27                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
            " 28      [21, 24, 27]  1     53832  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]\n",
            "Model Summary: 577 layers, 87063912 parameters, 87063912 gradients, 246.9 GFLOPs\n",
            "\n",
            "Transferred 27/757 items from yolov5/yolov5s.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 125 weight (no decay), 128 weight, 128 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/gdrive/MyDrive/CopyTrash/dataset/train' images and labels...5720 found, 107 missing, 0 empty, 0 corrupt: 100% 5827/5827 [04:59<00:00, 19.49it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/gdrive/MyDrive/CopyTrash/dataset/train/obj1218_frame0000050.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/gdrive/MyDrive/CopyTrash/dataset/train.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (2.1GB ram): 100% 5827/5827 [00:54<00:00, 106.33it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/gdrive/MyDrive/CopyTrash/dataset/val' images and labels...820 found, 0 missing, 1 empty, 0 corrupt: 100% 820/820 [00:44<00:00, 18.23it/s] \n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/gdrive/MyDrive/CopyTrash/dataset/val.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.3GB ram): 100% 820/820 [00:08<00:00, 91.78it/s]\n",
            "Plotting labels to yolov5/runs/train/yoloIncKV/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.92 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1myolov5/runs/train/yoloIncKV\u001b[0m\n",
            "Starting training for 11 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      0/10     4.58G   0.09006   0.02896   0.03375         7       416: 100% 729/729 [35:59<00:00,  2.96s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 52/52 [01:12<00:00,  1.40s/it]\n",
            "                 all        820       1064     0.0053     0.0274    0.00243    0.00052\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      1/10     4.99G   0.08436   0.02996    0.0298         7       416: 100% 729/729 [35:38<00:00,  2.93s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 52/52 [01:13<00:00,  1.40s/it]\n",
            "                 all        820       1064     0.0933      0.088     0.0297    0.00664\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      2/10     4.99G   0.06924   0.02772   0.02189         9       416: 100% 729/729 [35:27<00:00,  2.92s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 52/52 [01:12<00:00,  1.39s/it]\n",
            "                 all        820       1064      0.199      0.259      0.161     0.0579\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      3/10     4.99G   0.05619   0.02596   0.01731         8       416: 100% 729/729 [35:22<00:00,  2.91s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 52/52 [01:11<00:00,  1.37s/it]\n",
            "                 all        820       1064      0.273      0.305      0.269      0.115\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      4/10     4.99G   0.05022   0.02416   0.01354         7       416: 100% 729/729 [35:21<00:00,  2.91s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 52/52 [01:11<00:00,  1.37s/it]\n",
            "                 all        820       1064      0.506      0.242      0.288      0.126\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      5/10     4.99G   0.04559   0.02277   0.01073        28       416:  69% 506/729 [24:34<10:50,  2.92s/it]"
          ]
        }
      ],
      "source": [
        "!python /content/gdrive/MyDrive/CopyTrash/dataset/yolov5/train.py --img 416 --batch 8 --epochs 11 --data /content/gdrive/MyDrive/CopyTrash/dataset/yolov5/deep_sea_kv.yaml --cfg /content/gdrive/MyDrive/CopyTrash/dataset/yolov5/models/inc.yaml --name yoloIncKV --cach --save-period 1 --patience 3 --exist-ok"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If resuking"
      ],
      "metadata": {
        "id": "A7oVJShL8lbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./yolov5/train.py --img 416 --batch 8 --epochs 10 --data /content/gdrive/.shortcut-targets-by-id/1JOd-VQfnnHL0lQNQhWQVZkpmHmNlr-m_/dataset/trash_ICRA19/dataset/yolov5/deep_sea_sai.yaml --cfg /content/gdrive/.shortcut-targets-by-id/1JOd-VQfnnHL0lQNQhWQVZkpmHmNlr-m_/dataset/trash_ICRA19/dataset/yolov5/models/inc.yaml --name Inception --cach --resume True --save-period 1"
      ],
      "metadata": {
        "id": "JsnrhmuM8mwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtfi9tcKv3El"
      },
      "source": [
        "Yolov5x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "722LVKOPsmM7"
      },
      "outputs": [],
      "source": [
        "!python ./yolov5/train.py --img 416 --batch 8 --epochs 10 --data /content/gdrive/.shortcut-targets-by-id/1JOd-VQfnnHL0lQNQhWQVZkpmHmNlr-m_/dataset/trash_ICRA19/dataset/yolov5/deep_sea_sai.yaml --cfg /content/gdrive/.shortcut-targets-by-id/1JOd-VQfnnHL0lQNQhWQVZkpmHmNlr-m_/dataset/trash_ICRA19/dataset/yolov5/models/yolov5x.yaml --name Inception --cach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22YQGH5QKyLl"
      },
      "outputs": [],
      "source": [
        "!python /content/gdrive/.shortcut-targets-by-id/1wiYTA8v9a4HYq9Vf2eG-DhBAPLA6AGa4/trash_ICRA19/dataset/yolov5/detect.py --source /content/gdrive/.shortcut-targets-by-id/1wiYTA8v9a4HYq9Vf2eG-DhBAPLA6AGa4/trash_ICRA19/dataset/new/ --weights /content/gdrive/.shortcut-targets-by-id/1wiYTA8v9a4HYq9Vf2eG-DhBAPLA6AGa4/trash_ICRA19/dataset/yolov5/runs/train/name5/weights/best.pt --img 416 --conf 0.50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xl4R-3L_PvHT"
      },
      "source": [
        "Validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGT_YjOoOm8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3efdcdf4-b2f2-446b-81a7-b1d085db5bb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/gdrive/.shortcut-targets-by-id/1wiYTA8v9a4HYq9Vf2eG-DhBAPLA6AGa4/trash_ICRA19/dataset/yolov5/deep_sea_kv.yaml, weights=['/content/gdrive/.shortcut-targets-by-id/1wiYTA8v9a4HYq9Vf2eG-DhBAPLA6AGa4/trash_ICRA19/dataset/yolov5/runs/train/yolo5vs/weights/best.pt'], batch_size=32, imgsz=416, conf_thres=0.001, iou_thres=0.65, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5/runs/val, name=exp, exist_ok=False, half=True, dnn=False\n",
            "YOLOv5 ðŸš€ v6.1-35-g932dc78 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 213 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/gdrive/.shortcut-targets-by-id/1wiYTA8v9a4HYq9Vf2eG-DhBAPLA6AGa4/trash_ICRA19/dataset/val.cache' images and labels... 820 found, 0 missing, 1 empty, 0 corrupt: 100% 820/820 [00:00<?, ?it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 26/26 [00:54<00:00,  2.09s/it]\n",
            "                 all        820       1064    0.00755      0.243     0.0088    0.00232\n",
            "             plastic        820        853     0.0124      0.245    0.00846    0.00167\n",
            "                 bio        820         70   0.000123      0.157   8.09e-05   1.99e-05\n",
            "                 rov        820        141     0.0101      0.326     0.0179    0.00528\n",
            "Speed: 0.1ms pre-process, 6.6ms inference, 3.1ms NMS per image at shape (32, 3, 416, 416)\n",
            "Results saved to \u001b[1myolov5/runs/val/exp9\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python /content/gdrive/.shortcut-targets-by-id/1wiYTA8v9a4HYq9Vf2eG-DhBAPLA6AGa4/trash_ICRA19/dataset/yolov5/val.py --weights /content/gdrive/.shortcut-targets-by-id/1wiYTA8v9a4HYq9Vf2eG-DhBAPLA6AGa4/trash_ICRA19/dataset/yolov5/runs/train/yolo5vs/weights/best.pt --data /content/gdrive/.shortcut-targets-by-id/1wiYTA8v9a4HYq9Vf2eG-DhBAPLA6AGa4/trash_ICRA19/dataset/yolov5/deep_sea_kv.yaml --img 416 --iou 0.65 --half "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIGJxQZOQT-T"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31VsyE6yQVDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b04d9bd7-31e7-414f-f3de-43e1f77755b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/gdrive/MyDrive/FYP/debris/debris2/dataset/trash_ICRA19/dataset/yolov5/deep_sea_sai.yaml, weights=['/content/gdrive/MyDrive/FYP/debris/debris2/dataset/trash_ICRA19/dataset/yolov5/runs/train/InceptionNew2/weights/best.pt'], batch_size=32, imgsz=416, conf_thres=0.001, iou_thres=0.65, task=test, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5/runs/val, name=exp, exist_ok=False, half=True, dnn=False\n",
            "YOLOv5 ðŸš€ v6.1-35-g932dc78 torch 1.10.0+cu111 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 452 layers, 87019192 parameters, 0 gradients, 246.6 GFLOPs\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mScanning '/content/gdrive/.shortcut-targets-by-id/1JOd-VQfnnHL0lQNQhWQVZkpmHmNlr-m_/dataset/trash_ICRA19/dataset/test.cache' images and labels... 1144 found, 0 missing, 0 empty, 0 corrupt: 100% 1144/1144 [00:00<?, ?it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 36/36 [33:05<00:00, 55.17s/it]\n",
            "                 all       1144       1668      0.662      0.521      0.551      0.251\n",
            "             plastic       1144        937      0.668      0.681      0.682      0.307\n",
            "                 bio       1144        396      0.776      0.389       0.49      0.229\n",
            "                 rov       1144        335      0.541      0.493      0.481      0.216\n",
            "Speed: 1.3ms pre-process, 1724.6ms inference, 4.1ms NMS per image at shape (32, 3, 416, 416)\n",
            "Results saved to \u001b[1myolov5/runs/val/exp11\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python ./yolov5/val.py --weights /content/gdrive/MyDrive/FYP/debris/debris2/dataset/trash_ICRA19/dataset/yolov5/runs/train/InceptionNew2/weights/best.pt --data /content/gdrive/MyDrive/FYP/debris/debris2/dataset/trash_ICRA19/dataset/yolov5/deep_sea_sai.yaml --img 416 --iou 0.65 --half --task test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./yolov5/val.py --weights /content/gdrive/MyDrive/FYP/debris/debris2/dataset/trash_ICRA19/dataset/yolov5/runs/train/YoloIncUno4/weights/best.pt --data /content/gdrive/MyDrive/FYP/debris/debris2/dataset/trash_ICRA19/dataset/yolov5/deep_sea_sai.yaml --img 416 --iou 0.65 --half --task test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzjLJ5WJl0qn",
        "outputId": "f1ed8010-257c-4153-8236-0c22578db12c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file './yolov5/val.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./yolov5/train.py --img 416 --batch 8 --epochs 10 --data /content/gdrive/MyDrive/FYP/debris/debris2/dataset/trash_ICRA19/dataset/yolov5/deep_sea_sai.yaml --cfg /content/gdrive/MyDrive/FYP/debris/debris2/dataset/trash_ICRA19/dataset/yolov5/models/inc.yaml --weights /content/gdrive/MyDrive/FYP/debris/debris2/dataset/trash_ICRA19/dataset/yolov5/runs/train/InceptionNew2/weights/best.pt --name YoloIncUno --cach --save-period 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giHuFQ-WPMG4",
        "outputId": "8a0a43a6-3f19-4449-90ef-58b1c080b00c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/gdrive/MyDrive/FYP/debris/debris2/dataset/trash_ICRA19/dataset/yolov5/runs/train/InceptionNew2/weights/best.pt, cfg=/content/gdrive/MyDrive/FYP/debris/debris2/dataset/trash_ICRA19/dataset/yolov5/models/inc.yaml, data=/content/gdrive/MyDrive/FYP/debris/debris2/dataset/trash_ICRA19/dataset/yolov5/deep_sea_sai.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=8, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=YoloIncUno, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mâš ï¸ YOLOv5 is out of date by 111 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
            "YOLOv5 ðŸš€ v6.1-35-g932dc78 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
            "  1                -1  1     13120  models.common.Conv                      [80, 160, 1, 2]               \n",
            "  2                -1  1    230720  models.common.Conv                      [160, 160, 3, 1]              \n",
            "  3                 1  1    640320  models.common.Conv                      [160, 160, 5, 1]              \n",
            "  4                 0  1         0  torch.nn.modules.pooling.MaxPool2d      [3, 2, 1]                     \n",
            "  5      [1, 2, 3, 4]  1         0  models.common.Concat                    [1]                           \n",
            "  6                -1  4    373120  models.common.C3                        [560, 160, 4]                 \n",
            "  7                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
            "  8                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
            "  9                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
            " 10                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
            " 11                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
            " 12                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
            " 13                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
            " 14                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
            " 18                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
            " 19                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 20           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 21                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
            " 22                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
            " 23          [-1, 18]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
            " 25                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
            " 26          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 27                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
            " 28      [21, 24, 27]  1     53832  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]\n",
            "Model Summary: 577 layers, 87063912 parameters, 87063912 gradients, 246.9 GFLOPs\n",
            "\n",
            "Transferred 756/757 items from /content/gdrive/MyDrive/FYP/debris/debris2/dataset/trash_ICRA19/dataset/yolov5/runs/train/InceptionNew2/weights/best.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 125 weight (no decay), 128 weight, 128 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/gdrive/.shortcut-targets-by-id/1JOd-VQfnnHL0lQNQhWQVZkpmHmNlr-m_/dataset/trash_ICRA19/dataset/train.cache' images and labels... 5720 found, 107 missing, 0 empty, 0 corrupt: 100% 5827/5827 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/gdrive/.shortcut-targets-by-id/1JOd-VQfnnHL0lQNQhWQVZkpmHmNlr-m_/dataset/trash_ICRA19/dataset/train/obj1218_frame0000050.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (2.1GB ram): 100% 5827/5827 [01:08<00:00, 85.24it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/gdrive/.shortcut-targets-by-id/1JOd-VQfnnHL0lQNQhWQVZkpmHmNlr-m_/dataset/trash_ICRA19/dataset/val.cache' images and labels... 820 found, 0 missing, 1 empty, 0 corrupt: 100% 820/820 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.3GB ram): 100% 820/820 [00:10<00:00, 75.71it/s]\n",
            "Plotting labels to yolov5/runs/train/YoloIncUno4/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.92 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1myolov5/runs/train/YoloIncUno4\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       0/9     4.63G   0.02126    0.0122  0.001151         7       416: 100% 729/729 [35:42<00:00,  2.94s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 52/52 [01:11<00:00,  1.37s/it]\n",
            "                 all        820       1064      0.529      0.437      0.456       0.28\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       1/9     5.04G   0.02199   0.01248  0.001391         7       416: 100% 729/729 [35:19<00:00,  2.91s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 52/52 [01:11<00:00,  1.37s/it]\n",
            "                 all        820       1064      0.457      0.422      0.425      0.257\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       2/9     5.04G   0.02381   0.01275  0.001405         9       416: 100% 729/729 [35:15<00:00,  2.90s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 52/52 [01:11<00:00,  1.37s/it]\n",
            "                 all        820       1064      0.328      0.467      0.369      0.204\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       3/9     5.04G   0.02402   0.01332  0.001586         8       416: 100% 729/729 [35:40<00:00,  2.94s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 52/52 [01:12<00:00,  1.39s/it]\n",
            "                 all        820       1064       0.44      0.316       0.37      0.228\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       4/9     5.04G   0.02442   0.01339  0.001777         7       416: 100% 729/729 [35:44<00:00,  2.94s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 52/52 [01:12<00:00,  1.40s/it]\n",
            "                 all        820       1064      0.318      0.458      0.399      0.228\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       5/9     5.04G   0.02345   0.01294  0.001663         9       416: 100% 729/729 [35:44<00:00,  2.94s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 52/52 [01:12<00:00,  1.39s/it]\n",
            "                 all        820       1064      0.412      0.343      0.352      0.204\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       6/9     5.04G   0.02288   0.01278  0.001517        11       416: 100% 729/729 [35:44<00:00,  2.94s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 52/52 [01:12<00:00,  1.39s/it]\n",
            "                 all        820       1064      0.367      0.402      0.378      0.226\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       7/9     5.04G   0.02189   0.01233  0.001288         9       416: 100% 729/729 [35:44<00:00,  2.94s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 52/52 [01:12<00:00,  1.39s/it]\n",
            "                 all        820       1064      0.409      0.403      0.391      0.231\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       8/9     5.04G   0.02116   0.01212  0.001239         6       416: 100% 729/729 [35:44<00:00,  2.94s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 52/52 [01:12<00:00,  1.39s/it]\n",
            "                 all        820       1064      0.483      0.395      0.419       0.27\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       9/9     5.04G   0.02058   0.01198 0.0008934        30       416:  28% 201/729 [09:51<25:51,  2.94s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/FYP/debris/debris2/dataset/trash_ICRA19/dataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6D25gG9PNf0",
        "outputId": "a5b04730-8422-48a8-8819-b148ff3e2733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/FYP/debris/debris2/dataset/trash_ICRA19/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/gdrive/MyDrive/FYP/debris/debris2/dataset/trash_ICRA19/dataset/yolov5/runs/train/name5/weights/last.pt --data /content/gdrive/MyDrive/FYP/debris/debris2/dataset/trash_ICRA19/dataset/yolov5/deep_sea.yaml"
      ],
      "metadata": {
        "id": "uwviXX9dPlq9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "yolov5s.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}